# BinEgo-360° Workshop & Challenge @ **ICCV 2025**
Official website → <https://x360dataset.github.io/BinEgo-360/>

---

## 1.  Website Overview
| Section              | What the section delivers                                                                                                                                                                                  |
|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Workshop portal**  | Agenda, keynote speakers, venue & contact info for the half-day BinEgo-360° workshop, held 19 Oct 2025 at the Hawaii Convention Center, Honolulu, alongside ICCV 2025. |
| **Challenge hub**    | Rules, timeline and baseline scores for the public Kaggle competition (Classification + Temporal Action Localization) based on the **360+x** multi-modal dataset.    |
| **Dataset showcase** | Concise stats, GIF montage, download links (HR / LR), the CVPR 2024 paper, and baseline code for 360+x.                                                             |

---

## 2.  Section-by-Section Breakdown

### 2.1  Overview
Explains the vision: fusing **binocular egocentric** and **360° panoramic** views with audio, text and geo-metadata to mimic human perception. Key topics listed: embodied 360° reasoning, multi-modal scene understanding, stereo vision, open-world learning & domain adaptation. :contentReference[oaicite:28]{index=28}

### 2.2  Keynote Speakers
Name | Affiliation  
---|---  
**Addison Lin Wang** | NTU Singapore  
**Dima Damen** | University of Bristol  
**Bernard Ghanem** | KAUST  
Speaker headshots are circular thumbnails that scale up on hover; each name links to the speaker’s personal page. :contentReference[oaicite:29]{index=29}

### 2.3  Programme
A two-column table lays out the half-day schedule from 09:00 to 12:35, alternating row colours for readability. :contentReference[oaicite:30]{index=30}

### 2.4  Call for Papers
Details an invited-paper model (submission deadline **13 July 2025**) with a Google Form link placeholder. :contentReference[oaicite:31]{index=31}

### 2.5  Challenge
* **Dataset**: 2 152 videos (8.58 M frames / 67.8 h) across 38 classes; viewpoints cover 360° pano, binocular & monocular ego, third-person front; modalities include 6-ch spatial audio, GPS + weather, text. © CC BY-NC-SA 4.0 with faces auto-blurred. :contentReference[oaicite:32]{index=32}
* **Tracks**
    1. **Classification** – metric: top-1 accuracy (baseline 80.62 %).
    2. **Temporal Action Localization** – metric: mAP@{0.5, 0.75, 0.95} (baseline avg 17.6 ). :contentReference[oaicite:33]{index=33}
* **Timeline (AoE)**: Dataset release 1 Jun 2025 → submissions close 10 Aug 2025 → winners announced at workshop 19-20 Oct 2025. :contentReference[oaicite:34]{index=34}
* **Submission rules**: ≤ 5 members/team, 5 uploads/track, tech report & poster required for winners, no overlapping external data. :contentReference[oaicite:35]{index=35}
* **Prizes**: Insta360 X5 camera, GPU cloud credits (~£5-15 k) via SCAN, gift vouchers, and workshop registration for the 1st & 2nd winners sponsored by Tencent. Sponsors prominently thanked. :contentReference[oaicite:36]{index=36}

### 2.6  Ethics & Broader Impact
States consent, blurring, non-commercial licence, anti-surveillance stance, and potential benefits to robotics, AR/VR & assistive tech. :contentReference[oaicite:37]{index=37}

### 2.7  Organisers & Technical Committee
Seven core organisers + four technical leads, each with avatar, affiliation and personal-site link. Contact email: **j.jiao@bham.ac.uk**. :contentReference[oaicite:38]{index=38}

### 2.8  Sponsors
Logo grid for **Insta360**, **SCAN**, **Allsee**, and **Tencent** with external links. :contentReference[oaicite:39]{index=39}

### 2.9  Publication
BibTeX snippet for citing the foundational *360+x* CVPR 2024 paper. :contentReference[oaicite:40]{index=40}

---

## 3.  Licence

Website code © 2025 BinEgo-360° Organising Committee.  
Content released under **CCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License**.